# IoT-Human-Activity-Recognition

## Overview
This project presents a Human Activity Recognition system using wearable sensors, machine learning, and an Android app for real-time classification of 14 different activities.

## Technologies
- **Wearable Sensors**: Inertial Motion Unit (IMU) sensors including accelerometers and gyroscopes for data collection.
- **Machine Learning**: Deep learning models, especially Convolutional Neural Networks (CNNs), for activity classification.
- **Mobile Application**: Android app for displaying classified activities in real-time.

## Machine Learning Details
- **Data Processing & Preprocessing**: The system uses windowing and feature extraction techniques on time-series sensor data.
- **Model Architecture**: We implemented several models, including a 3-layer CNN, a 6-layer CNN, and tree-structured models for activity classification.
- **Curriculum Learning**: Models were trained using a curriculum learning strategy, incrementally increasing training data to improve model adaptability and accuracy.
- **Model Evaluation**: The models were evaluated on various datasets, ensuring robustness and reliability.

## Mobile Application
- **Design Philosophy**: The app follows Nielsen’s 6 stage ‘Design Thinking 101’ process, emphasizing user-centric design and usability.
- **Features**: Includes features for sensor connection, real-time data processing, user account creation, and historical data storage and visualization.

## System Implementation
- **Integration**: Please see the report for a detailed description of how the sensors, machine learning models, and mobile application are integrated to form a complete end-to-end system and a step-by-step guide to setting up and using the system.

## Contributors
John Chen 
Sean Strain 
Szymon Ciciala 


